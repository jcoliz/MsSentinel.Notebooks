{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# User Risk Score Sample\n",
    "\n",
    "This sample notebook demonstrates how to retrieve data from Microsoft Sentinel Data lake, calculate a security risk score based on the data, and store it back to a custom lake table. We calculates a **100-point user risk score** for each user by analyzing authentication patterns, application access, administrative activities, and security incidents across 4 data tables (SigninLogs, EntraUsers, AuditLogs, SecurityAlert).\n",
    "\n",
    "## References\n",
    "\n",
    "* [Available workspace tables](https://learn.microsoft.com/en-us/azure/azure-monitor/reference/tables-index)\n",
    "* [Available system tables](https://learn.microsoft.com/en-us/azure/sentinel/datalake/enable-data-connectors)\n",
    "* [Microsoft Sentinel Provider class](https://learn.microsoft.com/en-us/azure/sentinel/datalake/sentinel-provider-class-reference)\n",
    "* [Notebook examples](https://learn.microsoft.com/en-us/azure/sentinel/datalake/notebook-examples)\n",
    "\n",
    "## Risk Categories (100 points)\n",
    "\n",
    "- **Sign-in Behavior (30 pts)** - IP/device diversity, frequency vs. baseline\n",
    "- **Application Access (25 pts)** - Apps and resources accessed\n",
    "- **Privileged Activity (20 pts)** - Admin operations, high-risk actions\n",
    "- **Security Alerts (15 pts)** - Active alerts and severity\n",
    "- **Geographic (5 pts)** - Location patterns\n",
    "- **Temporal (5 pts)** - Off-hours activity\n",
    "\n",
    "**Risk Levels:** Low (0-30), Medium (31-60), High (61-100)\n",
    "\n",
    "## Key Features\n",
    "\n",
    "‚úÖ Multi-dimensional analysis combining behavior, privilege, and threat data  \n",
    "‚úÖ Department-aware baselines for context-sensitive scoring  \n",
    "‚úÖ Graceful degradation (works with 2-4 tables)  \n",
    "‚úÖ Production-ready with error handling and metadata  \n",
    "‚úÖ Outputs to `UserRiskScores_SPRK` table (27 fields)\n",
    "\n",
    "## Use Cases\n",
    "\n",
    "- **Insider threats:** High admin activity + alerts + unusual patterns\n",
    "- **Compromised accounts:** Geographic anomalies + security alerts\n",
    "- **Privileged users:** Continuous monitoring of admin operations\n",
    "- **Investigation prioritization:** Quantitative risk-based triage\n",
    "\n",
    "**Full documentation:** [`USER_RISK_SCORE_DESIGN.md`](USER_RISK_SCORE_DESIGN.md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup & Configuration\n",
    "\n",
    "In this section, we'll set up our environment and configure the parameters for our risk scoring analysis.\n",
    "\n",
    "**What we're doing:**\n",
    "- Import required PySpark libraries for data processing\n",
    "- Initialize the Microsoft Sentinel provider to access data lake tables\n",
    "- Configure analysis parameters (time window, workspace, thresholds)\n",
    "\n",
    "**Key Configuration Parameters:**\n",
    "- `ANALYSIS_DAYS`: How far back to look for data (default: 14 days)\n",
    "- `WORKSPACE_NAME`: Your Sentinel workspace name\n",
    "- `BUSINESS_HOUR_START/END`: Define normal working hours for temporal risk analysis\n",
    "- `MIN_SIGNIN_THRESHOLD`: Minimum sign-ins required to calculate a meaningful risk score\n",
    "\n",
    "**Expected Output:**\n",
    "You'll see confirmation of the configuration settings that will be used for the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from sentinel_lake.providers import MicrosoftSentinelProvider\n",
    "from pyspark.sql.functions import (\n",
    "    col, count, countDistinct, sum, when, hour, lit, expr, \n",
    "    current_timestamp, date_sub, avg, collect_list, coalesce,\n",
    "    from_json, get_json_object\n",
    ")\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "WORKSPACE_NAME = \"<YOUR_WORKSPACE_NAME>\"\n",
    "\n",
    "# Analysis Configuration (can be overridden)\n",
    "ANALYSIS_DAYS = 14\n",
    "MIN_SIGNIN_THRESHOLD = 3\n",
    "BUSINESS_HOUR_START = 6\n",
    "BUSINESS_HOUR_END = 18\n",
    "\n",
    "# ============================================================\n",
    "\n",
    "# Initialize Sentinel provider\n",
    "sentinel_provider = MicrosoftSentinelProvider(spark)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"USER RISK SCORE CONFIGURATION\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Analysis Window: {ANALYSIS_DAYS} days\")\n",
    "print(f\"Workspace: {WORKSPACE_NAME}\")\n",
    "print(f\"Business Hours: {BUSINESS_HOUR_START}:00 - {BUSINESS_HOUR_END}:00\")\n",
    "print(f\"Minimum Sign-in Threshold: {MIN_SIGNIN_THRESHOLD} events\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Loading (4 Tables)\n",
    "\n",
    "In this section, we load data from **4 different Sentinel tables** to build a comprehensive risk profile. Each table is loaded in a separate cell for independent troubleshooting.\n",
    "\n",
    "**Table 1: SigninLogs** - User authentication and access patterns\n",
    "**Table 2: EntraUsers** - User identity and organizational context\n",
    "**Table 3: AuditLogs** - Administrative and privileged operations\n",
    "**Table 4: SecurityAlert** - Active security incidents and detections"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Load SigninLogs\n",
    "\n",
    "Load sign-in events for behavioral analysis:\n",
    "- Filters for Member users only\n",
    "- Includes IP addresses, devices, applications\n",
    "- Used for access pattern analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä Loading Table 1: SigninLogs...\")\n",
    "signin_df = (\n",
    "    sentinel_provider.read_table('SigninLogs', WORKSPACE_NAME)\n",
    "    .filter(\n",
    "        (col(\"UserType\") == \"Member\") & \n",
    "        (col(\"UserId\").isNotNull()) &\n",
    "        (col(\"TimeGenerated\") >= expr(f\"current_timestamp() - INTERVAL {ANALYSIS_DAYS} DAYS\"))\n",
    "    )\n",
    "    .select(\n",
    "        \"UserId\", \"UserPrincipalName\", \"UserDisplayName\",\n",
    "        \"IPAddress\", \"UserAgent\", \"AppId\", \"ResourceId\",\n",
    "        \"TimeGenerated\", \"Location\"\n",
    "    )\n",
    "    .persist()\n",
    ")\n",
    "print(f\"‚úÖ Loaded {signin_df.count()} sign-in events\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Load EntraUsers\n",
    "\n",
    "Load user profile information:\n",
    "- Department, country, job title\n",
    "- Used for enrichment and baseline calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä Loading Table 2: EntraUsers...\")\n",
    "users_df = (\n",
    "    sentinel_provider.read_table('EntraUsers')\n",
    "    .filter(\n",
    "        (col(\"id\").isNotNull()) &\n",
    "        (col(\"id\") != \"\")\n",
    "    )\n",
    "    .select(\"id\", \"displayName\", \"mail\", \"department\", \"country\", \"jobTitle\", \"accountEnabled\")\n",
    "    .dropDuplicates([\"id\"])\n",
    "    .persist()\n",
    ")\n",
    "print(f\"‚úÖ Loaded {users_df.count()} user profiles\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Load AuditLogs\n",
    "\n",
    "Load administrative activity logs:\n",
    "- Tracks privileged operations\n",
    "- InitiatedBy field is JSON: `{\"user\": {\"userPrincipalName\": \"...\"}}`\n",
    "- Uses `get_json_object()` to parse and extract user principal name\n",
    "- Only includes user-initiated actions (filters out app-initiated)\n",
    "\n",
    "**Note:** This table may not be available in all environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä Loading Table 3: AuditLogs...\")\n",
    "try:\n",
    "    # Import here in case this cell is run independently\n",
    "    from pyspark.sql.functions import col, expr, get_json_object\n",
    "    \n",
    "    # InitiatedBy is a JSON string: {\"user\": {\"userPrincipalName\": \"user@domain.com\", ...}}\n",
    "    audit_df = (\n",
    "        sentinel_provider.read_table('AuditLogs', WORKSPACE_NAME)\n",
    "        .filter(\n",
    "            col(\"ActivityDateTime\") >= expr(f\"current_timestamp() - INTERVAL {ANALYSIS_DAYS} DAYS\")\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"UserPrincipalName\",\n",
    "            get_json_object(col(\"InitiatedBy\"), \"$.user.userPrincipalName\")\n",
    "        )\n",
    "        .select(\n",
    "            \"UserPrincipalName\",\n",
    "            \"OperationName\",\n",
    "            \"Category\",\n",
    "            \"Result\",\n",
    "            \"ActivityDateTime\"\n",
    "        )\n",
    "        .filter(col(\"UserPrincipalName\").isNotNull())\n",
    "        .persist()\n",
    "    )\n",
    "    audit_available = True\n",
    "    print(f\"‚úÖ Loaded {audit_df.count()} audit log entries (user-initiated only)\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  AuditLogs not available: {str(e)}\")\n",
    "    print(f\"‚ÑπÔ∏è  Will continue without privileged activity scoring\")\n",
    "    audit_available = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Load SecurityAlert\n",
    "\n",
    "Load active security alerts:\n",
    "- Only unresolved alerts (Status: New or InProgress)\n",
    "- Provides direct threat indicators\n",
    "- Used for alert-based risk scoring\n",
    "\n",
    "**Note:** This table may not be available in all environments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä Loading Table 4: SecurityAlert...\")\n",
    "try:\n",
    "    security_alert_df = (\n",
    "        sentinel_provider.read_table('SecurityAlert', WORKSPACE_NAME)\n",
    "        .filter(\n",
    "            (col(\"Status\").isin([\"New\", \"InProgress\"])) &\n",
    "            (col(\"TimeGenerated\") >= expr(f\"current_timestamp() - INTERVAL {ANALYSIS_DAYS} DAYS\"))\n",
    "        )\n",
    "        .select(\n",
    "            \"AlertName\",\n",
    "            \"AlertSeverity\",\n",
    "            \"CompromisedEntity\",\n",
    "            \"Status\",\n",
    "            \"TimeGenerated\",\n",
    "            \"Tactics\"\n",
    "        )\n",
    "        .filter(col(\"CompromisedEntity\").isNotNull())\n",
    "        .persist()\n",
    "    )\n",
    "    alert_available = True\n",
    "    print(f\"‚úÖ Loaded {security_alert_df.count()} active security alerts\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  SecurityAlert not available: {str(e)}\")\n",
    "    print(f\"‚ÑπÔ∏è  Will continue without alert scoring\")\n",
    "    alert_available = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 Data Loading Summary\n",
    "\n",
    "Display which tables were successfully loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\"*60)\n",
    "print(\"Data Loading Summary:\")\n",
    "print(f\"  ‚úÖ SigninLogs: Available\")\n",
    "print(f\"  ‚úÖ EntraUsers: Available\")\n",
    "print(f\"  {'‚úÖ' if audit_available else '‚ùå'} AuditLogs: {'Available' if audit_available else 'Not Available'}\")\n",
    "print(f\"  {'‚úÖ' if alert_available else '‚ùå'} SecurityAlert: {'Available' if alert_available else 'Not Available'}\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calculate Base Metrics from SigninLogs\n",
    "\n",
    "Now we'll aggregate the sign-in data to calculate per-user metrics that will feed into our risk scoring.\n",
    "\n",
    "**Metrics Calculated:**\n",
    "- **Sign-in Behavior**: Unique IP count, unique device count, total sign-ins\n",
    "- **Application Access**: Unique app count, unique resource count\n",
    "- **Temporal Patterns**: Off-hours sign-in count and percentage\n",
    "\n",
    "These metrics form the foundation for behavioral risk assessment.\n",
    "\n",
    "**Expected Output:**\n",
    "- Count of users with calculated metrics\n",
    "- Each user will have aggregated statistics from their sign-in activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîç Calculating sign-in behavior metrics...\")\n",
    "\n",
    "# Aggregate sign-in metrics per user\n",
    "signin_metrics = (\n",
    "    signin_df\n",
    "    .groupBy(\"UserId\", \"UserPrincipalName\", \"UserDisplayName\")\n",
    "    .agg(\n",
    "        # Sign-in behavior metrics\n",
    "        countDistinct(\"IPAddress\").alias(\"unique_ip_count\"),\n",
    "        countDistinct(\"UserAgent\").alias(\"unique_device_count\"),\n",
    "        count(\"*\").alias(\"total_signins\"),\n",
    "        \n",
    "        # Application access metrics\n",
    "        countDistinct(\"AppId\").alias(\"unique_app_count\"),\n",
    "        countDistinct(\"ResourceId\").alias(\"unique_resource_count\"),\n",
    "        \n",
    "        # Temporal metrics\n",
    "        sum(\n",
    "            when(\n",
    "                (hour(\"TimeGenerated\") < BUSINESS_HOUR_START) | \n",
    "                (hour(\"TimeGenerated\") >= BUSINESS_HOUR_END), \n",
    "                1\n",
    "            ).otherwise(0)\n",
    "        ).alias(\"offhours_signins\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Calculate off-hours percentage\n",
    "signin_metrics = signin_metrics.withColumn(\n",
    "    \"offhours_signin_percent\",\n",
    "    (col(\"offhours_signins\") / col(\"total_signins\") * 100).cast(\"float\")\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Calculated metrics for {signin_metrics.count()} users\")\n",
    "\n",
    "# Show sample of calculated metrics\n",
    "print(\"\\nüìä Sample of Calculated Metrics (Top 10 users by sign-in count):\")\n",
    "signin_metrics.orderBy(col(\"total_signins\").desc()).show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate Privileged Activity Metrics (AuditLogs)\n",
    "\n",
    "In this section, we analyze **administrative operations** from AuditLogs to identify privileged activity patterns.\n",
    "\n",
    "**What we're doing:**\n",
    "- Define a list of high-risk operations (role changes, user deletions, policy updates)\n",
    "- Aggregate audit metrics per user: total admin operations, high-risk operation count, unique operations\n",
    "- Handle gracefully when AuditLogs aren't available (create empty DataFrame)\n",
    "\n",
    "**Risk Considerations:**\n",
    "- Users with many admin operations may have elevated access\n",
    "- Certain operations (e.g., \"Add member to role\") are inherently higher risk\n",
    "- Unusual volume of administrative activity can indicate compromise or insider threat\n",
    "\n",
    "**Expected Output:**\n",
    "- Count of users who performed administrative operations\n",
    "- Empty metrics (all zeros) if AuditLogs unavailable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if audit_available:\n",
    "    print(\"üîç Calculating privileged activity metrics...\")\n",
    "    \n",
    "    # Define high-risk operations\n",
    "    high_risk_ops = [\n",
    "        \"Add member to role\",\n",
    "        \"Remove member from role\",\n",
    "        \"Delete user\",\n",
    "        \"Update application\",\n",
    "        \"Add owner to application\",\n",
    "        \"Update policy\",\n",
    "        \"Delete application\"\n",
    "    ]\n",
    "    \n",
    "    # Aggregate audit metrics per user\n",
    "    audit_metrics = (\n",
    "        audit_df\n",
    "        .groupBy(\"UserPrincipalName\")\n",
    "        .agg(\n",
    "            count(\"*\").alias(\"total_admin_operations\"),\n",
    "            sum(\n",
    "                when(col(\"OperationName\").isin(high_risk_ops), 1)\n",
    "                .otherwise(0)\n",
    "            ).alias(\"high_risk_operations\"),\n",
    "            countDistinct(\"OperationName\").alias(\"unique_operations\"),\n",
    "            collect_list(\"OperationName\").alias(\"operation_list\")\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Calculated audit metrics for {audit_metrics.count()} users with admin activity\")\n",
    "    \n",
    "    # Show sample\n",
    "    print(\"\\nüìä Top 10 Users by Administrative Operations:\")\n",
    "    audit_metrics.orderBy(col(\"total_admin_operations\").desc()).show(10, truncate=False)\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Skipping privileged activity metrics (AuditLogs not available)\")\n",
    "    # Create empty DataFrame with expected schema for downstream joins\n",
    "    audit_metrics = spark.createDataFrame(\n",
    "        [], \n",
    "        \"UserPrincipalName string, total_admin_operations int, high_risk_operations int, unique_operations int\"\n",
    "    )\n",
    "    print(\"‚ÑπÔ∏è  Empty audit_metrics DataFrame created for compatibility\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calculate Security Alert Metrics\n",
    "\n",
    "In this section, we analyze **active security alerts** from SecurityAlert table to identify users with current security concerns.\n",
    "\n",
    "**What we're doing:**\n",
    "- Aggregate alert data per compromised entity (user)\n",
    "- Count total active alerts for each user\n",
    "- Calculate weighted severity score (High=4, Medium=2, Low=1)\n",
    "- Collect alert types for context\n",
    "- Handle gracefully when SecurityAlert isn't available\n",
    "\n",
    "**Risk Considerations:**\n",
    "- Active alerts are the strongest indicator of current compromise\n",
    "- High-severity alerts warrant immediate attention\n",
    "- Multiple alerts on same user suggest persistent threat\n",
    "- Alert types (Tactics) provide insight into attack patterns\n",
    "\n",
    "**Expected Output:**\n",
    "- Count of users with active security alerts\n",
    "- Empty metrics (all zeros) if SecurityAlert unavailable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if alert_available:\n",
    "    print(\"üîç Calculating security alert metrics...\")\n",
    "    \n",
    "    # Aggregate alert metrics per compromised entity (user)\n",
    "    alert_metrics = (\n",
    "        security_alert_df\n",
    "        .groupBy(\"CompromisedEntity\")\n",
    "        .agg(\n",
    "            count(\"*\").alias(\"active_alert_count\"),\n",
    "            sum(\n",
    "                when(col(\"AlertSeverity\") == \"High\", 4)\n",
    "                .when(col(\"AlertSeverity\") == \"Medium\", 2)\n",
    "                .when(col(\"AlertSeverity\") == \"Low\", 1)\n",
    "                .otherwise(0)\n",
    "            ).alias(\"alert_severity_score\"),\n",
    "            collect_list(\"AlertName\").alias(\"alert_types\")\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    print(f\"‚úÖ Calculated alert metrics for {alert_metrics.count()} users with active alerts\")\n",
    "    \n",
    "    # Show sample\n",
    "    print(\"\\nüö® Top 10 Users by Alert Severity Score:\")\n",
    "    alert_metrics.orderBy(col(\"alert_severity_score\").desc()).show(10, truncate=False)\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Skipping security alert metrics (SecurityAlert not available)\")\n",
    "    # Create empty DataFrame with expected schema for downstream joins\n",
    "    alert_metrics = spark.createDataFrame(\n",
    "        [],\n",
    "        \"CompromisedEntity string, active_alert_count int, alert_severity_score int\"\n",
    "    )\n",
    "    print(\"‚ÑπÔ∏è  Empty alert_metrics DataFrame created for compatibility\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Join All Metrics\n",
    "\n",
    "Now we combine data from all 4 tables into a single unified view for each user.\n",
    "\n",
    "**What we're doing:**\n",
    "- Start with signin_metrics as the base (all users with sign-ins)\n",
    "- LEFT JOIN EntraUsers for organizational context (department, country, job title)\n",
    "- LEFT JOIN audit_metrics for admin activity (many users will have nulls ‚Üí fill with 0)\n",
    "- LEFT JOIN alert_metrics for security alerts (many users will have nulls ‚Üí fill with 0)\n",
    "\n",
    "**Join Strategy:**\n",
    "- Use LEFT joins to retain all users who signed in\n",
    "- Fill nulls for users without admin activity or alerts\n",
    "- Result: One row per user with all metrics combined\n",
    "\n",
    "**Expected Output:**\n",
    "- Count of users in combined dataset\n",
    "- All users from sign-ins with enriched data from other tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üîó Joining metrics from all tables...\")\n",
    "\n",
    "# Start with sign-in metrics as base\n",
    "combined_metrics = signin_metrics\n",
    "\n",
    "# Join user profile data (EntraUsers)\n",
    "combined_metrics = (\n",
    "    combined_metrics\n",
    "    .join(users_df, combined_metrics.UserId == users_df.id, \"left\")\n",
    "    .select(\n",
    "        col(\"UserId\"),\n",
    "        col(\"UserPrincipalName\"),\n",
    "        col(\"UserDisplayName\"),\n",
    "        col(\"unique_ip_count\"),\n",
    "        col(\"unique_device_count\"),\n",
    "        col(\"total_signins\"),\n",
    "        col(\"unique_app_count\"),\n",
    "        col(\"unique_resource_count\"),\n",
    "        col(\"offhours_signins\"),\n",
    "        col(\"offhours_signin_percent\"),\n",
    "        col(\"department\"),\n",
    "        col(\"country\"),\n",
    "        col(\"jobTitle\")\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"  ‚úÖ Joined EntraUsers data\")\n",
    "\n",
    "# Join audit metrics (if available)\n",
    "if audit_available:\n",
    "    combined_metrics = (\n",
    "        combined_metrics\n",
    "        .join(\n",
    "            audit_metrics,\n",
    "            combined_metrics.UserPrincipalName == audit_metrics.UserPrincipalName,\n",
    "            \"left\"\n",
    "        )\n",
    "        .drop(audit_metrics.UserPrincipalName)\n",
    "    )\n",
    "    # Fill nulls for users with no admin activity\n",
    "    combined_metrics = combined_metrics.fillna(\n",
    "        {\"total_admin_operations\": 0, \"high_risk_operations\": 0, \"unique_operations\": 0}\n",
    "    )\n",
    "    print(f\"  ‚úÖ Joined AuditLogs data (nulls filled with 0)\")\n",
    "else:\n",
    "    # Add columns with 0 values\n",
    "    combined_metrics = combined_metrics.withColumn(\"total_admin_operations\", lit(0))\n",
    "    combined_metrics = combined_metrics.withColumn(\"high_risk_operations\", lit(0))\n",
    "    combined_metrics = combined_metrics.withColumn(\"unique_operations\", lit(0))\n",
    "    print(f\"  ‚ÑπÔ∏è  AuditLogs not available - added zero columns\")\n",
    "\n",
    "# Join alert metrics (if available)\n",
    "if alert_available:\n",
    "    combined_metrics = (\n",
    "        combined_metrics\n",
    "        .join(\n",
    "            alert_metrics,\n",
    "            combined_metrics.UserPrincipalName == alert_metrics.CompromisedEntity,\n",
    "            \"left\"\n",
    "        )\n",
    "        .drop(alert_metrics.CompromisedEntity)\n",
    "    )\n",
    "    # Fill nulls for users with no alerts\n",
    "    combined_metrics = combined_metrics.fillna(\n",
    "        {\"active_alert_count\": 0, \"alert_severity_score\": 0}\n",
    "    )\n",
    "    print(f\"  ‚úÖ Joined SecurityAlert data (nulls filled with 0)\")\n",
    "else:\n",
    "    # Add columns with 0 values\n",
    "    combined_metrics = combined_metrics.withColumn(\"active_alert_count\", lit(0))\n",
    "    combined_metrics = combined_metrics.withColumn(\"alert_severity_score\", lit(0))\n",
    "    print(f\"  ‚ÑπÔ∏è  SecurityAlert not available - added zero columns\")\n",
    "\n",
    "print(f\"\\n‚úÖ Combined metrics ready for {combined_metrics.count()} users\")\n",
    "\n",
    "# Show sample of combined data\n",
    "print(\"\\nüìä Sample Combined Metrics (First 5 users):\")\n",
    "combined_metrics.select(\n",
    "    \"UserPrincipalName\", \"department\", \"total_signins\", \n",
    "    \"unique_ip_count\", \"total_admin_operations\", \"active_alert_count\"\n",
    ").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Calculate Department Baselines\n",
    "\n",
    "To detect **frequency anomalies**, we need to establish what \"normal\" sign-in activity looks like for each department.\n",
    "\n",
    "**What we're doing:**\n",
    "- Calculate average sign-in frequency per department\n",
    "- Calculate global average as fallback for users without department\n",
    "- Join baseline back to user data for comparison\n",
    "\n",
    "**Why This Matters:**\n",
    "- Engineering teams may have different normal patterns than Sales\n",
    "- Allows context-aware risk scoring (high activity for Sales may be normal, but unusual for HR)\n",
    "- Users significantly above their department baseline get higher frequency risk scores\n",
    "\n",
    "**Expected Output:**\n",
    "- Global average sign-in count\n",
    "- Each user gets a baseline_signins value (department avg or global avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìä Calculating department baselines...\")\n",
    "\n",
    "# Calculate department-level average sign-in frequency\n",
    "dept_baselines = (\n",
    "    combined_metrics\n",
    "    .filter(col(\"department\").isNotNull())\n",
    "    .groupBy(\"department\")\n",
    "    .agg(avg(\"total_signins\").alias(\"dept_avg_signins\"))\n",
    ")\n",
    "\n",
    "# Calculate global average as fallback\n",
    "global_avg = combined_metrics.agg(\n",
    "    avg(\"total_signins\").alias(\"global_avg_signins\")\n",
    ").collect()[0][\"global_avg_signins\"]\n",
    "\n",
    "print(f\"  ‚ÑπÔ∏è  Global average sign-ins: {global_avg:.1f}\")\n",
    "\n",
    "# Join baselines to user data - drop any existing baseline columns first\n",
    "if \"baseline_signins\" in combined_metrics.columns:\n",
    "    combined_metrics = combined_metrics.drop(\"baseline_signins\")\n",
    "if \"dept_avg_signins\" in combined_metrics.columns:\n",
    "    combined_metrics = combined_metrics.drop(\"dept_avg_signins\")\n",
    "\n",
    "combined_metrics = (\n",
    "    combined_metrics\n",
    "    .join(\n",
    "        dept_baselines,\n",
    "        combined_metrics.department == dept_baselines.department,\n",
    "        \"left\"\n",
    "    )\n",
    "    .withColumn(\n",
    "        \"baseline_signins\",\n",
    "        coalesce(dept_baselines[\"dept_avg_signins\"], lit(global_avg))\n",
    "    )\n",
    "    .select(\n",
    "        combined_metrics[\"*\"],  # All original columns\n",
    "        col(\"baseline_signins\")  # New baseline column\n",
    "    )\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Baselines calculated and joined\")\n",
    "\n",
    "# Show sample with baselines\n",
    "print(\"\\nüìä Sample with Department Baselines (First 10 users):\")\n",
    "combined_metrics.select(\n",
    "    \"UserPrincipalName\", \"department\", \"total_signins\", \"baseline_signins\"\n",
    ").show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Calculate Individual Risk Scores\n",
    "\n",
    "Now we'll calculate **9 individual risk scores** based on the metrics we've collected. Each risk factor is scored on its own scale, then combined into category subscores.\n",
    "\n",
    "**Risk Categories & Scoring:**\n",
    "\n",
    "1. **Sign-in Behavior (30 points total)**\n",
    "   - IP Risk (0-10): Based on unique IP count\n",
    "   - Device Risk (0-10): Based on unique device count\n",
    "   - Frequency Risk (0-10): Based on comparison to department baseline\n",
    "\n",
    "2. **Application Access (25 points total)**\n",
    "   - App Risk (0-12): Based on unique application count\n",
    "   - Resource Risk (0-13): Based on unique resource count\n",
    "\n",
    "3. **Privileged Activity (20 points total)** - if AuditLogs available\n",
    "   - Admin Operations Risk (0-10): Total admin operations volume\n",
    "   - High-Risk Operations (0-10): Count of sensitive operations\n",
    "\n",
    "4. **Security Alerts (15 points total)** - if SecurityAlert available\n",
    "   - Alert Count (0-8): Number of active alerts\n",
    "   - Alert Severity (0-7): Weighted severity score\n",
    "\n",
    "5. **Geographic Risk (5 points)**: Based on IP diversity\n",
    "\n",
    "6. **Temporal Risk (5 points)**: Based on off-hours activity percentage\n",
    "\n",
    "**Total Possible: 100 points**\n",
    "\n",
    "**Expected Output:**\n",
    "- Each user gets 9+ risk factor scores\n",
    "- All scores ready for combination into total risk score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéØ Calculating individual risk scores...\")\n",
    "\n",
    "# Import here in case this cell runs independently\n",
    "from pyspark.sql.functions import col, when, lit\n",
    "\n",
    "# Start with combined_metrics\n",
    "risk_scores = combined_metrics\n",
    "\n",
    "# ========================================\n",
    "# Sign-in Behavior Risk (30 points)\n",
    "# ========================================\n",
    "\n",
    "# IP Risk (0-10)\n",
    "risk_scores = risk_scores.withColumn(\"ip_risk_score\",\n",
    "    when(col(\"unique_ip_count\") <= 2, 0)\n",
    "    .when(col(\"unique_ip_count\") <= 5, 3)\n",
    "    .when(col(\"unique_ip_count\") <= 10, 7)\n",
    "    .otherwise(10)\n",
    ")\n",
    "\n",
    "# Device Risk (0-10)\n",
    "risk_scores = risk_scores.withColumn(\"device_risk_score\",\n",
    "    when(col(\"unique_device_count\") <= 2, 0)\n",
    "    .when(col(\"unique_device_count\") <= 4, 3)\n",
    "    .when(col(\"unique_device_count\") <= 7, 6)\n",
    "    .otherwise(10)\n",
    ")\n",
    "\n",
    "# Frequency Risk (0-10) - Compare to baseline\n",
    "risk_scores = risk_scores.withColumn(\"frequency_ratio\", \n",
    "    col(\"total_signins\") / col(\"baseline_signins\")\n",
    ")\n",
    "risk_scores = risk_scores.withColumn(\"frequency_risk_score\",\n",
    "    when(col(\"frequency_ratio\") < 1.0, 0)\n",
    "    .when(col(\"frequency_ratio\") < 2.0, 3)\n",
    "    .when(col(\"frequency_ratio\") < 3.0, 6)\n",
    "    .otherwise(10)\n",
    ")\n",
    "\n",
    "print(\"  ‚úÖ Sign-in behavior risk calculated (30 points)\")\n",
    "\n",
    "# ========================================\n",
    "# Application Access Risk (25 points)\n",
    "# ========================================\n",
    "\n",
    "# App Risk (0-12)\n",
    "risk_scores = risk_scores.withColumn(\"app_risk_score\",\n",
    "    when(col(\"unique_app_count\") <= 5, 0)\n",
    "    .when(col(\"unique_app_count\") <= 10, 4)\n",
    "    .when(col(\"unique_app_count\") <= 15, 8)\n",
    "    .otherwise(12)\n",
    ")\n",
    "\n",
    "# Resource Risk (0-13)\n",
    "risk_scores = risk_scores.withColumn(\"resource_risk_score\",\n",
    "    when(col(\"unique_resource_count\") <= 3, 0)\n",
    "    .when(col(\"unique_resource_count\") <= 6, 4)\n",
    "    .when(col(\"unique_resource_count\") <= 10, 8)\n",
    "    .otherwise(13)\n",
    ")\n",
    "\n",
    "print(\"  ‚úÖ Application access risk calculated (25 points)\")\n",
    "\n",
    "# ========================================\n",
    "# Privileged Activity Risk (20 points)\n",
    "# ========================================\n",
    "\n",
    "if audit_available:\n",
    "    # Admin Operations Risk (0-10)\n",
    "    risk_scores = risk_scores.withColumn(\"admin_ops_risk_score\",\n",
    "        when(col(\"total_admin_operations\") == 0, 0)\n",
    "        .when(col(\"total_admin_operations\") <= 5, 3)\n",
    "        .when(col(\"total_admin_operations\") <= 15, 7)\n",
    "        .otherwise(10)\n",
    "    )\n",
    "    \n",
    "    # High-Risk Operations (0-10)\n",
    "    risk_scores = risk_scores.withColumn(\"high_risk_ops_score\",\n",
    "        when(col(\"high_risk_operations\") == 0, 0)\n",
    "        .when(col(\"high_risk_operations\") <= 2, 4)\n",
    "        .when(col(\"high_risk_operations\") <= 5, 7)\n",
    "        .otherwise(10)\n",
    "    )\n",
    "    print(\"  ‚úÖ Privileged activity risk calculated (20 points)\")\n",
    "else:\n",
    "    # No audit data - set to 0\n",
    "    risk_scores = risk_scores.withColumn(\"admin_ops_risk_score\", lit(0))\n",
    "    risk_scores = risk_scores.withColumn(\"high_risk_ops_score\", lit(0))\n",
    "    print(\"  ‚ÑπÔ∏è  Privileged activity risk set to 0 (AuditLogs not available)\")\n",
    "\n",
    "# ========================================\n",
    "# Security Alert Risk (15 points)\n",
    "# ========================================\n",
    "\n",
    "if alert_available:\n",
    "    # Active Alert Count (0-8)\n",
    "    risk_scores = risk_scores.withColumn(\"alert_count_score\",\n",
    "        when(col(\"active_alert_count\") == 0, 0)\n",
    "        .when(col(\"active_alert_count\") == 1, 3)\n",
    "        .when(col(\"active_alert_count\") <= 3, 6)\n",
    "        .otherwise(8)\n",
    "    )\n",
    "    \n",
    "    # Alert Severity (0-7)\n",
    "    risk_scores = risk_scores.withColumn(\"alert_severity_risk_score\",\n",
    "        when(col(\"alert_severity_score\") == 0, 0)\n",
    "        .when(col(\"alert_severity_score\") <= 3, 2)\n",
    "        .when(col(\"alert_severity_score\") <= 7, 5)\n",
    "        .otherwise(7)\n",
    "    )\n",
    "    print(\"  ‚úÖ Security alert risk calculated (15 points)\")\n",
    "else:\n",
    "    # No alert data - set to 0\n",
    "    risk_scores = risk_scores.withColumn(\"alert_count_score\", lit(0))\n",
    "    risk_scores = risk_scores.withColumn(\"alert_severity_risk_score\", lit(0))\n",
    "    print(\"  ‚ÑπÔ∏è  Security alert risk set to 0 (SecurityAlert not available)\")\n",
    "\n",
    "# ========================================\n",
    "# Geographic Risk (5 points)\n",
    "# ========================================\n",
    "\n",
    "# Simplified based on IP diversity\n",
    "risk_scores = risk_scores.withColumn(\"geographic_risk_score\",\n",
    "    when(col(\"unique_ip_count\") <= 3, 0)\n",
    "    .when(col(\"unique_ip_count\") <= 6, 2)\n",
    "    .when(col(\"unique_ip_count\") <= 10, 4)\n",
    "    .otherwise(5)\n",
    ")\n",
    "\n",
    "print(\"  ‚úÖ Geographic risk calculated (5 points)\")\n",
    "\n",
    "# ========================================\n",
    "# Temporal Risk (5 points)\n",
    "# ========================================\n",
    "\n",
    "risk_scores = risk_scores.withColumn(\"temporal_risk_score\",\n",
    "    when(col(\"offhours_signin_percent\") <= 10, 0)\n",
    "    .when(col(\"offhours_signin_percent\") <= 25, 2)\n",
    "    .when(col(\"offhours_signin_percent\") <= 50, 4)\n",
    "    .otherwise(5)\n",
    ")\n",
    "\n",
    "print(\"  ‚úÖ Temporal risk calculated (5 points)\")\n",
    "\n",
    "print(\"\\n‚úÖ All individual risk factors calculated\")\n",
    "\n",
    "# Show sample of risk scores\n",
    "print(\"\\nüìä Sample Risk Scores (First 5 users):\")\n",
    "risk_scores.select(\n",
    "    \"UserPrincipalName\",\n",
    "    \"ip_risk_score\",\n",
    "    \"device_risk_score\",\n",
    "    \"frequency_risk_score\",\n",
    "    \"app_risk_score\",\n",
    "    \"resource_risk_score\",\n",
    "    \"admin_ops_risk_score\",\n",
    "    \"high_risk_ops_score\",\n",
    "    \"alert_count_score\",\n",
    "    \"alert_severity_risk_score\",\n",
    "    \"geographic_risk_score\",\n",
    "    \"temporal_risk_score\"\n",
    ").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Calculate Individual Risk Scores\n",
    "\n",
    "Now we'll calculate **9 individual risk scores** based on the metrics we've collected. Each risk factor is scored on its own scale, then combined into category subscores.\n",
    "\n",
    "**Risk Categories & Scoring:**\n",
    "\n",
    "1. **Sign-in Behavior (30 points total)**\n",
    "   - IP Risk (0-10): Based on unique IP count\n",
    "   - Device Risk (0-10): Based on unique device count\n",
    "   - Frequency Risk (0-10): Based on comparison to department baseline\n",
    "\n",
    "2. **Application Access (25 points total)**\n",
    "   - App Risk (0-12): Based on unique application count\n",
    "   - Resource Risk (0-13): Based on unique resource count\n",
    "\n",
    "3. **Privileged Activity (20 points total)** - if AuditLogs available\n",
    "   - Admin Operations Risk (0-10): Total admin operations volume\n",
    "   - High-Risk Operations (0-10): Count of sensitive operations\n",
    "\n",
    "4. **Security Alerts (15 points total)** - if SecurityAlert available\n",
    "   - Alert Count (0-8): Number of active alerts\n",
    "   - Alert Severity (0-7): Weighted severity score\n",
    "\n",
    "5. **Geographic Risk (5 points)**: Based on IP diversity\n",
    "\n",
    "6. **Temporal Risk (5 points)**: Based on off-hours activity percentage\n",
    "\n",
    "**Total Possible: 100 points**\n",
    "\n",
    "**Expected Output:**\n",
    "- Each user gets 9+ risk factor scores\n",
    "- All scores ready for combination into total risk score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üéØ Calculating individual risk scores...\")\n",
    "\n",
    "# Import here in case this cell runs independently\n",
    "from pyspark.sql.functions import col, when, lit\n",
    "\n",
    "# Start with combined_metrics\n",
    "risk_scores = combined_metrics\n",
    "\n",
    "# ========================================\n",
    "# Sign-in Behavior Risk (30 points)\n",
    "# ========================================\n",
    "\n",
    "# IP Risk (0-10)\n",
    "risk_scores = risk_scores.withColumn(\"ip_risk_score\",\n",
    "    when(col(\"unique_ip_count\") <= 2, 0)\n",
    "    .when(col(\"unique_ip_count\") <= 5, 3)\n",
    "    .when(col(\"unique_ip_count\") <= 10, 7)\n",
    "    .otherwise(10)\n",
    ")\n",
    "\n",
    "# Device Risk (0-10)\n",
    "risk_scores = risk_scores.withColumn(\"device_risk_score\",\n",
    "    when(col(\"unique_device_count\") <= 2, 0)\n",
    "    .when(col(\"unique_device_count\") <= 4, 3)\n",
    "    .when(col(\"unique_device_count\") <= 7, 6)\n",
    "    .otherwise(10)\n",
    ")\n",
    "\n",
    "# Frequency Risk (0-10) - Compare to baseline\n",
    "risk_scores = risk_scores.withColumn(\"frequency_ratio\", \n",
    "    col(\"total_signins\") / col(\"baseline_signins\")\n",
    ")\n",
    "risk_scores = risk_scores.withColumn(\"frequency_risk_score\",\n",
    "    when(col(\"frequency_ratio\") < 1.0, 0)\n",
    "    .when(col(\"frequency_ratio\") < 2.0, 3)\n",
    "    .when(col(\"frequency_ratio\") < 3.0, 6)\n",
    "    .otherwise(10)\n",
    ")\n",
    "\n",
    "print(\"  ‚úÖ Sign-in behavior risk calculated (30 points)\")\n",
    "\n",
    "# ========================================\n",
    "# Application Access Risk (25 points)\n",
    "# ========================================\n",
    "\n",
    "# App Risk (0-12)\n",
    "risk_scores = risk_scores.withColumn(\"app_risk_score\",\n",
    "    when(col(\"unique_app_count\") <= 5, 0)\n",
    "    .when(col(\"unique_app_count\") <= 10, 4)\n",
    "    .when(col(\"unique_app_count\") <= 15, 8)\n",
    "    .otherwise(12)\n",
    ")\n",
    "\n",
    "# Resource Risk (0-13)\n",
    "risk_scores = risk_scores.withColumn(\"resource_risk_score\",\n",
    "    when(col(\"unique_resource_count\") <= 3, 0)\n",
    "    .when(col(\"unique_resource_count\") <= 6, 4)\n",
    "    .when(col(\"unique_resource_count\") <= 10, 8)\n",
    "    .otherwise(13)\n",
    ")\n",
    "\n",
    "print(\"  ‚úÖ Application access risk calculated (25 points)\")\n",
    "\n",
    "# ========================================\n",
    "# Privileged Activity Risk (20 points)\n",
    "# ========================================\n",
    "\n",
    "if audit_available:\n",
    "    # Admin Operations Risk (0-10)\n",
    "    risk_scores = risk_scores.withColumn(\"admin_ops_risk_score\",\n",
    "        when(col(\"total_admin_operations\") == 0, 0)\n",
    "        .when(col(\"total_admin_operations\") <= 5, 3)\n",
    "        .when(col(\"total_admin_operations\") <= 15, 7)\n",
    "        .otherwise(10)\n",
    "    )\n",
    "    \n",
    "    # High-Risk Operations (0-10)\n",
    "    risk_scores = risk_scores.withColumn(\"high_risk_ops_score\",\n",
    "        when(col(\"high_risk_operations\") == 0, 0)\n",
    "        .when(col(\"high_risk_operations\") <= 2, 4)\n",
    "        .when(col(\"high_risk_operations\") <= 5, 7)\n",
    "        .otherwise(10)\n",
    "    )\n",
    "    print(\"  ‚úÖ Privileged activity risk calculated (20 points)\")\n",
    "else:\n",
    "    # No audit data - set to 0\n",
    "    risk_scores = risk_scores.withColumn(\"admin_ops_risk_score\", lit(0))\n",
    "    risk_scores = risk_scores.withColumn(\"high_risk_ops_score\", lit(0))\n",
    "    print(\"  ‚ÑπÔ∏è  Privileged activity risk set to 0 (AuditLogs not available)\")\n",
    "\n",
    "# ========================================\n",
    "# Security Alert Risk (15 points)\n",
    "# ========================================\n",
    "\n",
    "if alert_available:\n",
    "    # Active Alert Count (0-8)\n",
    "    risk_scores = risk_scores.withColumn(\"alert_count_score\",\n",
    "        when(col(\"active_alert_count\") == 0, 0)\n",
    "        .when(col(\"active_alert_count\") == 1, 3)\n",
    "        .when(col(\"active_alert_count\") <= 3, 6)\n",
    "        .otherwise(8)\n",
    "    )\n",
    "    \n",
    "    # Alert Severity (0-7)\n",
    "    risk_scores = risk_scores.withColumn(\"alert_severity_risk_score\",\n",
    "        when(col(\"alert_severity_score\") == 0, 0)\n",
    "        .when(col(\"alert_severity_score\") <= 3, 2)\n",
    "        .when(col(\"alert_severity_score\") <= 7, 5)\n",
    "        .otherwise(7)\n",
    "    )\n",
    "    print(\"  ‚úÖ Security alert risk calculated (15 points)\")\n",
    "else:\n",
    "    # No alert data - set to 0\n",
    "    risk_scores = risk_scores.withColumn(\"alert_count_score\", lit(0))\n",
    "    risk_scores = risk_scores.withColumn(\"alert_severity_risk_score\", lit(0))\n",
    "    print(\"  ‚ÑπÔ∏è  Security alert risk set to 0 (SecurityAlert not available)\")\n",
    "\n",
    "# ========================================\n",
    "# Geographic Risk (5 points)\n",
    "# ========================================\n",
    "\n",
    "# Simplified based on IP diversity\n",
    "risk_scores = risk_scores.withColumn(\"geographic_risk_score\",\n",
    "    when(col(\"unique_ip_count\") <= 3, 0)\n",
    "    .when(col(\"unique_ip_count\") <= 6, 2)\n",
    "    .when(col(\"unique_ip_count\") <= 10, 4)\n",
    "    .otherwise(5)\n",
    ")\n",
    "\n",
    "print(\"  ‚úÖ Geographic risk calculated (5 points)\")\n",
    "\n",
    "# ========================================\n",
    "# Temporal Risk (5 points)\n",
    "# ========================================\n",
    "\n",
    "risk_scores = risk_scores.withColumn(\"temporal_risk_score\",\n",
    "    when(col(\"offhours_signin_percent\") <= 10, 0)\n",
    "    .when(col(\"offhours_signin_percent\") <= 25, 2)\n",
    "    .when(col(\"offhours_signin_percent\") <= 50, 4)\n",
    "    .otherwise(5)\n",
    ")\n",
    "\n",
    "print(\"  ‚úÖ Temporal risk calculated (5 points)\")\n",
    "\n",
    "print(\"\\n‚úÖ All individual risk factors calculated\")\n",
    "\n",
    "# Show sample of risk scores\n",
    "print(\"\\nüìä Sample Risk Scores (First 5 users):\")\n",
    "risk_scores.select(\n",
    "    \"UserPrincipalName\",\n",
    "    \"ip_risk_score\",\n",
    "    \"device_risk_score\",\n",
    "    \"frequency_risk_score\",\n",
    "    \"app_risk_score\",\n",
    "    \"resource_risk_score\",\n",
    "    \"admin_ops_risk_score\",\n",
    "    \"high_risk_ops_score\",\n",
    "    \"alert_count_score\",\n",
    "    \"alert_severity_risk_score\",\n",
    "    \"geographic_risk_score\",\n",
    "    \"temporal_risk_score\"\n",
    ").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Calculate Composite Scores\n",
    "\n",
    "Now we combine the individual risk scores into **category subscores** and calculate the **total risk score** (0-100 points).\n",
    "\n",
    "**What we're doing:**\n",
    "\n",
    "1. **Category Subscores**: Sum individual scores within each category\n",
    "   - `signin_behavior_score` (0-30): IP + Device + Frequency\n",
    "   - `application_access_score` (0-25): App + Resource\n",
    "   - `privileged_activity_score` (0-20): Admin Ops + High-Risk Ops\n",
    "   - `security_alert_score` (0-15): Alert Count + Alert Severity\n",
    "\n",
    "2. **Total Risk Score** (0-100): Sum all category scores + Geographic + Temporal\n",
    "\n",
    "3. **Risk Level Classification**:\n",
    "   - **Low**: 0-30 points\n",
    "   - **Medium**: 31-60 points\n",
    "   - **High**: 61-100 points\n",
    "\n",
    "4. **Alert Flag**: Boolean indicator for users with active security alerts\n",
    "\n",
    "**Expected Output:**\n",
    "- Each user gets a total_risk_score (0-100)\n",
    "- Risk level classification (Low/Medium/High)\n",
    "- Summary statistics showing score distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"üìà Calculating composite risk scores...\")\n",
    "\n",
    "# Import here in case this cell runs independently\n",
    "from pyspark.sql.functions import col, when, lit\n",
    "\n",
    "# ========================================\n",
    "# Category Subscores\n",
    "# ========================================\n",
    "\n",
    "# Sign-in Behavior Score (0-30)\n",
    "risk_scores = risk_scores.withColumn(\"signin_behavior_score\",\n",
    "    col(\"ip_risk_score\") + col(\"device_risk_score\") + col(\"frequency_risk_score\")\n",
    ")\n",
    "\n",
    "# Application Access Score (0-25)\n",
    "risk_scores = risk_scores.withColumn(\"application_access_score\",\n",
    "    col(\"app_risk_score\") + col(\"resource_risk_score\")\n",
    ")\n",
    "\n",
    "# Privileged Activity Score (0-20)\n",
    "risk_scores = risk_scores.withColumn(\"privileged_activity_score\",\n",
    "    col(\"admin_ops_risk_score\") + col(\"high_risk_ops_score\")\n",
    ")\n",
    "\n",
    "# Security Alert Score (0-15)\n",
    "risk_scores = risk_scores.withColumn(\"security_alert_score\",\n",
    "    col(\"alert_count_score\") + col(\"alert_severity_risk_score\")\n",
    ")\n",
    "\n",
    "print(\"  ‚úÖ Category subscores calculated\")\n",
    "\n",
    "# ========================================\n",
    "# Total Risk Score (0-100)\n",
    "# ========================================\n",
    "\n",
    "risk_scores = risk_scores.withColumn(\"total_risk_score\",\n",
    "    col(\"signin_behavior_score\") +\n",
    "    col(\"application_access_score\") +\n",
    "    col(\"privileged_activity_score\") +\n",
    "    col(\"security_alert_score\") +\n",
    "    col(\"geographic_risk_score\") +\n",
    "    col(\"temporal_risk_score\")\n",
    ")\n",
    "\n",
    "print(\"  ‚úÖ Total risk score calculated\")\n",
    "\n",
    "# ========================================\n",
    "# Risk Level Classification\n",
    "# ========================================\n",
    "\n",
    "risk_scores = risk_scores.withColumn(\"risk_level\",\n",
    "    when(col(\"total_risk_score\") <= 30, \"Low\")\n",
    "    .when(col(\"total_risk_score\") <= 60, \"Medium\")\n",
    "    .otherwise(\"High\")\n",
    ")\n",
    "\n",
    "print(\"  ‚úÖ Risk level classification applied\")\n",
    "\n",
    "# ========================================\n",
    "# Alert Flag\n",
    "# ========================================\n",
    "\n",
    "if alert_available:\n",
    "    risk_scores = risk_scores.withColumn(\"has_active_alerts\",\n",
    "        when(col(\"active_alert_count\") > 0, True).otherwise(False)\n",
    "    )\n",
    "else:\n",
    "    risk_scores = risk_scores.withColumn(\"has_active_alerts\", lit(False))\n",
    "\n",
    "print(\"  ‚úÖ Alert flag added\")\n",
    "\n",
    "print(\"\\n‚úÖ All composite scores calculated\")\n",
    "\n",
    "# ========================================\n",
    "# Summary Statistics\n",
    "# ========================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RISK SCORE SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Risk level distribution\n",
    "risk_distribution = risk_scores.groupBy(\"risk_level\").count().orderBy(\"risk_level\")\n",
    "\n",
    "# Calculate total users for visualization\n",
    "total_users = risk_scores.count()\n",
    "\n",
    "# Show top 10 highest risk users\n",
    "print(\"\\nüî¥ Top 10 Highest Risk Users:\")\n",
    "risk_scores.select(\n",
    "    \"UserPrincipalName\",\n",
    "    \"department\",\n",
    "    \"total_risk_score\",\n",
    "    \"risk_level\",\n",
    "    \"signin_behavior_score\",\n",
    "    \"application_access_score\",\n",
    "    \"privileged_activity_score\",\n",
    "    \"security_alert_score\"\n",
    ").orderBy(col(\"total_risk_score\").desc()).show(10, truncate=False)\n",
    "\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ========================================\n",
    "# Visualization: Risk Level Distribution\n",
    "# ========================================\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Convert to pandas for easy plotting\n",
    "risk_dist_pd = risk_distribution.toPandas()\n",
    "\n",
    "# Create bar chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "bars = plt.bar(risk_dist_pd[\"risk_level\"], risk_dist_pd[\"count\"], \n",
    "               color=[\"#2ecc71\", \"#f39c12\", \"#e74c3c\"],  # Green, Orange, Red\n",
    "               edgecolor=\"black\", linewidth=1.2)\n",
    "\n",
    "# Add value labels on top of bars\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
    "             f\"{int(height)}\\n({int(height)/total_users*100:.1f}%)\",\n",
    "             ha=\"center\", va=\"bottom\", fontsize=12, fontweight=\"bold\")\n",
    "\n",
    "plt.xlabel(\"Risk Level\", fontsize=14, fontweight=\"bold\")\n",
    "plt.ylabel(\"Number of Users\", fontsize=14, fontweight=\"bold\")\n",
    "plt.title(f\"User Risk Level Distribution (Total: {total_users} users)\", \n",
    "          fontsize=16, fontweight=\"bold\", pad=20)\n",
    "plt.grid(axis=\"y\", alpha=0.3, linestyle=\"--\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nüìä Risk distribution chart generated\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Add Metadata & Final Selection\n",
    "\n",
    "In this section, we prepare the final output DataFrame by adding metadata and selecting the exact columns we want to write to the custom table.\n",
    "\n",
    "**What we're doing:**\n",
    "\n",
    "- Add timestamp columns: calculation_date, analysis window dates, TimeGenerated\n",
    "- Select and order all output columns (25+ fields)\n",
    "- Use coalesce() to ensure no null values for optional metrics\n",
    "- Order by total_risk_score descending for easy identification of high-risk users\n",
    "\n",
    "**Output Columns (27 total):**\n",
    "\n",
    "1. **Identity** (6): UserId, UserPrincipalName, UserDisplayName, department, country, jobTitle\n",
    "2. **Risk Scores** (8): total_risk_score, risk_level, 6 category subscores\n",
    "3. **Metrics** (9): Sign-in counts, app/resource counts, admin operations, alerts\n",
    "4. **Metadata** (4): calculation_date, analysis_start_date, analysis_end_date, TimeGenerated\n",
    "\n",
    "**Expected Output:**\n",
    "\n",
    "- Final DataFrame ready for writing to custom table\n",
    "- Ordered by risk score (highest first)\n",
    "- All columns properly named and typed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "print(\"üìù Preparing final output...\")\n",
    "\n",
    "# Calculate analysis date range\n",
    "analysis_end = datetime.now()\n",
    "analysis_start = analysis_end - timedelta(days=ANALYSIS_DAYS)\n",
    "\n",
    "# Add metadata columns\n",
    "risk_scores_final = (\n",
    "    risk_scores\n",
    "    .withColumn(\"calculation_date\", current_timestamp())\n",
    "    .withColumn(\"analysis_start_date\", lit(analysis_start))\n",
    "    .withColumn(\"analysis_end_date\", lit(analysis_end))\n",
    "    .withColumn(\"TimeGenerated\", current_timestamp())\n",
    ")\n",
    "\n",
    "print(\"  ‚úÖ Metadata columns added\")\n",
    "\n",
    "# Select final output columns in specific order\n",
    "output_df = risk_scores_final.select(\n",
    "    # ========================================\n",
    "    # Identity (6 columns)\n",
    "    # ========================================\n",
    "    col(\"UserId\"),\n",
    "    col(\"UserPrincipalName\"),\n",
    "    col(\"UserDisplayName\"),\n",
    "    col(\"department\"),\n",
    "    col(\"country\"),\n",
    "    col(\"jobTitle\"),\n",
    "\n",
    "    # ========================================\n",
    "    # Risk Scores (8 columns)\n",
    "    # ========================================\n",
    "    col(\"total_risk_score\"),\n",
    "    col(\"risk_level\"),\n",
    "    col(\"signin_behavior_score\"),\n",
    "    col(\"application_access_score\"),\n",
    "    col(\"privileged_activity_score\"),\n",
    "    col(\"security_alert_score\"),\n",
    "    col(\"geographic_risk_score\"),\n",
    "    col(\"temporal_risk_score\"),\n",
    "\n",
    "    # ========================================\n",
    "    # Sign-in Metrics (6 columns)\n",
    "    # ========================================\n",
    "\n",
    "    col(\"unique_ip_count\"),\n",
    "    col(\"unique_device_count\"),\n",
    "    col(\"total_signins\"),\n",
    "    col(\"unique_app_count\"),\n",
    "    col(\"unique_resource_count\"),\n",
    "    col(\"offhours_signin_percent\"),\n",
    "\n",
    "    # ========================================\n",
    "    # Privileged Activity Metrics (2 columns)\n",
    "    # ========================================\n",
    "    coalesce(col(\"total_admin_operations\"), lit(0)).alias(\"total_admin_operations\"),\n",
    "    coalesce(col(\"high_risk_operations\"), lit(0)).alias(\"high_risk_operations\"),\n",
    "\n",
    "    # ========================================\n",
    "    # Alert Metrics (3 columns)\n",
    "    # ========================================\n",
    "    coalesce(col(\"active_alert_count\"), lit(0)).alias(\"active_alert_count\"),\n",
    "    coalesce(col(\"alert_severity_score\"), lit(0)).alias(\"alert_severity_score\"),\n",
    "    col(\"has_active_alerts\"),\n",
    "\n",
    "    # ========================================\n",
    "    # Metadata (4 columns)\n",
    "    # ========================================\n",
    "    col(\"calculation_date\"),\n",
    "    col(\"analysis_start_date\"),\n",
    "    col(\"analysis_end_date\"),\n",
    "    col(\"TimeGenerated\")\n",
    ").orderBy(col(\"total_risk_score\").desc())\n",
    "\n",
    "print(\"  ‚úÖ Final output columns selected\")\n",
    "\n",
    "# Display summary\n",
    "user_count = output_df.count()\n",
    "column_count = len(output_df.columns)\n",
    "\n",
    "print(f\"\\n‚úÖ Final output prepared:\")\n",
    "print(f\"  üìä {user_count} users\")\n",
    "print(f\"  üìã {column_count} columns\")\n",
    "print(f\"  üéØ Ordered by total_risk_score (descending)\")\n",
    "\n",
    "# Show sample of final output\n",
    "print(\"\\nüìã Sample Final Output (Top 5 highest risk users):\")\n",
    "output_df.select(\n",
    "    \"UserPrincipalName\",\n",
    "    \"department\",\n",
    "    \"total_risk_score\",\n",
    "    \"risk_level\",\n",
    "    \"signin_behavior_score\",\n",
    "    \"application_access_score\",\n",
    "    \"privileged_activity_score\",\n",
    "    \"security_alert_score\"\n",
    ").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Results Analysis & Visualization\n",
    "\n",
    "Now that we have our final risk scores, let's analyze the results in detail to understand the risk landscape across our user population.\n",
    "\n",
    "**Analysis Sections:**\n",
    "\n",
    "1. **Top 10 Highest Risk Users** - Identify users requiring immediate attention\n",
    "2. **Risk Level Distribution** - Overall security posture visualization\n",
    "3. **Users with Active Alerts** - Security incidents requiring investigation\n",
    "4. **Users with Admin Activity** - Privileged access patterns\n",
    "5. **Risk Factor Contributions** - Which factors drive overall risk\n",
    "6. **Department Risk Analysis** - Organizational risk patterns\n",
    "7. **Summary Statistics** - Key metrics and percentages\n",
    "\n",
    "**Expected Insights:**\n",
    "\n",
    "- Identify high-risk users for investigation\n",
    "- Understand which risk factors are most significant\n",
    "- Spot organizational patterns (departments with elevated risk)\n",
    "- Quantify the overall security posture\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"RISK SCORE ANALYSIS RESULTS\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# ========================================\n",
    "# 1. Top 10 Highest Risk Users\n",
    "# ========================================\n",
    "\n",
    "print(\"\\nüî¥ Top 10 Highest Risk Users:\")\n",
    "output_df.select(\n",
    "    \"UserPrincipalName\",\n",
    "    \"department\",\n",
    "    \"total_risk_score\",\n",
    "    \"risk_level\",\n",
    "    \"signin_behavior_score\",\n",
    "    \"application_access_score\",\n",
    "    \"privileged_activity_score\",\n",
    "    \"security_alert_score\"\n",
    ").show(10, truncate=False)\n",
    "\n",
    "# ========================================\n",
    "# 2. Risk Level Distribution\n",
    "# ========================================\n",
    "\n",
    "print(\"\\nüìä Risk Level Distribution:\")\n",
    "risk_distribution = output_df.groupBy(\"risk_level\").count().orderBy(\"risk_level\")\n",
    "risk_distribution.show()\n",
    "\n",
    "# ========================================\n",
    "# 3. Users with Active Alerts\n",
    "# ========================================\n",
    "\n",
    "if alert_available:\n",
    "    alert_users = output_df.filter(col(\"has_active_alerts\") == True).count()\n",
    "    print(f\"\\n‚ö†Ô∏è  Users with Active Security Alerts: {alert_users}\")\n",
    "    \n",
    "    if alert_users > 0:\n",
    "        print(\"\\nüö® Top Users by Active Alerts:\")\n",
    "        output_df.filter(col(\"active_alert_count\") > 0)\\\n",
    "            .select(\n",
    "                \"UserPrincipalName\",\n",
    "                \"active_alert_count\",\n",
    "                \"alert_severity_score\",\n",
    "                \"total_risk_score\",\n",
    "                \"risk_level\"\n",
    "            )\\\n",
    "            .orderBy(col(\"active_alert_count\").desc())\\\n",
    "            .show(10, truncate=False)\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  SecurityAlert data not available - skipping alert analysis\")\n",
    "\n",
    "# ========================================\n",
    "# 4. Users with Administrative Activity\n",
    "# ========================================\n",
    "\n",
    "if audit_available:\n",
    "    admin_users = output_df.filter(col(\"total_admin_operations\") > 0).count()\n",
    "    print(f\"\\nüîë Users with Administrative Activity: {admin_users}\")\n",
    "    \n",
    "    if admin_users > 0:\n",
    "        print(\"\\nüë§ Top Users by Admin Operations:\")\n",
    "        output_df.filter(col(\"total_admin_operations\") > 0)\\\n",
    "            .select(\n",
    "                \"UserPrincipalName\",\n",
    "                \"total_admin_operations\",\n",
    "                \"high_risk_operations\",\n",
    "                \"total_risk_score\",\n",
    "                \"risk_level\"\n",
    "            )\\\n",
    "            .orderBy(col(\"total_admin_operations\").desc())\\\n",
    "            .show(10, truncate=False)\n",
    "else:\n",
    "    print(\"\\n‚ö†Ô∏è  AuditLogs data not available - skipping privileged activity analysis\")\n",
    "\n",
    "# ========================================\n",
    "# 5. Risk Factor Contribution Analysis\n",
    "# ========================================\n",
    "\n",
    "print(\"\\nüìà Average Risk Factor Contributions:\")\n",
    "output_df.select(\n",
    "    avg(\"signin_behavior_score\").alias(\"Avg_SignIn_Behavior\"),\n",
    "    avg(\"application_access_score\").alias(\"Avg_App_Access\"),\n",
    "    avg(\"privileged_activity_score\").alias(\"Avg_Privileged_Activity\"),\n",
    "    avg(\"security_alert_score\").alias(\"Avg_Security_Alerts\"),\n",
    "    avg(\"geographic_risk_score\").alias(\"Avg_Geographic\"),\n",
    "    avg(\"temporal_risk_score\").alias(\"Avg_Temporal\")\n",
    ").show(truncate=False)\n",
    "\n",
    "# ========================================\n",
    "# 6. Department Risk Analysis\n",
    "# ========================================\n",
    "\n",
    "print(\"\\nüè¢ Average Risk Score by Department (Top 10):\")\n",
    "output_df.filter(col(\"department\").isNotNull())\\\n",
    "    .groupBy(\"department\")\\\n",
    "    .agg(\n",
    "        avg(\"total_risk_score\").alias(\"avg_risk_score\"),\n",
    "        count(\"*\").alias(\"user_count\")\n",
    "    )\\\n",
    "    .orderBy(col(\"avg_risk_score\").desc())\\\n",
    "    .show(10, truncate=False)\n",
    "\n",
    "# ========================================\n",
    "# 7. Summary Statistics\n",
    "# ========================================\n",
    "\n",
    "high_risk_count = output_df.filter(col(\"risk_level\") == \"High\").count()\n",
    "medium_risk_count = output_df.filter(col(\"risk_level\") == \"Medium\").count()\n",
    "low_risk_count = output_df.filter(col(\"risk_level\") == \"Low\").count()\n",
    "total_users = output_df.count()\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"SUMMARY STATISTICS\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Total Users Analyzed: {total_users}\")\n",
    "print(f\"High Risk:   {high_risk_count:4d} ({high_risk_count/total_users*100:5.1f}%)\")\n",
    "print(f\"Medium Risk: {medium_risk_count:4d} ({medium_risk_count/total_users*100:5.1f}%)\")\n",
    "print(f\"Low Risk:    {low_risk_count:4d} ({low_risk_count/total_users*100:5.1f}%)\")\n",
    "\n",
    "if alert_available:\n",
    "    alert_user_count = output_df.filter(col(\"has_active_alerts\") == True).count()\n",
    "    print(f\"\\nUsers with Active Alerts: {alert_user_count} ({alert_user_count/total_users*100:5.1f}%)\")\n",
    "\n",
    "if audit_available:\n",
    "    admin_user_count = output_df.filter(col(\"total_admin_operations\") > 0).count()\n",
    "    print(f\"Users with Admin Activity: {admin_user_count} ({admin_user_count/total_users*100:5.1f}%)\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(\"\\n‚úÖ Analysis complete - output_df ready for writing to custom table\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Write to Custom Table\n",
    "\n",
    "Now we'll write our calculated risk scores to a custom Sentinel table for use in queries, workbooks, and analytics rules.\n",
    "\n",
    "**Required Permissions:**\n",
    "\n",
    "Writing to custom tables requires specific Azure permissions:\n",
    "- **Microsoft Sentinel Contributor** role on the workspace, OR\n",
    "- **Storage Blob Data Contributor** role on the underlying storage account\n",
    "- See: [Microsoft Sentinel RBAC roles](https://learn.microsoft.com/en-us/azure/sentinel/roles)\n",
    "\n",
    "**What we're doing:**\n",
    "\n",
    "- Write the `output_df` DataFrame to a custom table\n",
    "- Table name: `UserRiskScores_SPRK` (following the _SPRK convention for notebook-generated tables)\n",
    "- Mode: `overwrite` - replaces existing data with current analysis\n",
    "- Format: Delta Lake for ACID transactions\n",
    "\n",
    "**If you don't have write permissions:**\n",
    "\n",
    "The code includes fallback options:\n",
    "1. Export to CSV for manual ingestion\n",
    "2. Display results in notebook for analysis\n",
    "3. Contact your Sentinel administrator to request permissions\n",
    "\n",
    "**Custom Table Benefits:**\n",
    "\n",
    "- Query risk scores directly in KQL\n",
    "- Create workbooks and dashboards\n",
    "- Use in analytics rules for automated alerting\n",
    "- Join with other Sentinel tables for correlation\n",
    "\n",
    "**Expected Output:**\n",
    "\n",
    "- Confirmation message showing records written, OR\n",
    "- Permissions error with alternative export options\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "import sys\n",
    "import io\n",
    "import os\n",
    "\n",
    "print(\"\\nüíæ Writing risk scores to custom table...\")\n",
    "print(\"\\n‚ö†Ô∏è  Note: Writing custom tables requires Microsoft Sentinel Contributor permissions\")\n",
    "print(\"   If you don't have permissions, the data will remain in 'output_df' for analysis\\n\")\n",
    "\n",
    "# Custom table name - following the _SPRK convention\n",
    "CUSTOM_TABLE_NAME = \"UserRiskScores_SPRK\"\n",
    "write_success = False\n",
    "\n",
    "# Save original stderr\n",
    "original_stderr = sys.stderr\n",
    "\n",
    "try:\n",
    "    # Suppress stderr during the write attempt to avoid mixed output\n",
    "    sys.stderr = open(os.devnull, 'w')\n",
    "    \n",
    "    # Write using Sentinel provider's save_as_table method\n",
    "    # Saving to system tables, so no `database_name` needed\n",
    "    sentinel_provider.save_as_table(\n",
    "        output_df, \n",
    "        CUSTOM_TABLE_NAME,\n",
    "        write_options={\n",
    "            \"mode\": \"overwrite\",\n",
    "            \"mergeSchema\": \"true\"\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    write_success = True\n",
    "    \n",
    "    # Restore stderr before printing success\n",
    "    sys.stderr = original_stderr\n",
    "    \n",
    "    record_count = output_df.count()\n",
    "    print(f\"‚úÖ Successfully wrote {record_count} records to {CUSTOM_TABLE_NAME}\")\n",
    "    print(f\"\\nüìä Table Details:\")\n",
    "    print(f\"   Table Name: {CUSTOM_TABLE_NAME}\")\n",
    "    print(f\"   Records: {record_count}\")\n",
    "    print(f\"   Columns: {len(output_df.columns)}\")\n",
    "    print(f\"   Method: sentinel_provider.save_as_table()\")\n",
    "    \n",
    "    print(f\"\\nüîç Query in KQL:\")\n",
    "    print(f\"   {CUSTOM_TABLE_NAME}\")\n",
    "    print(f\"   | where risk_level == 'High'\")\n",
    "    print(f\"   | order by total_risk_score desc\")\n",
    "    \n",
    "except Exception as e:\n",
    "    # Restore stderr\n",
    "    sys.stderr = original_stderr\n",
    "    \n",
    "    print(f\"‚ùå Could not write to custom table\")\n",
    "    print(f\"\\nüìã Exception Details (for reporting):\")\n",
    "    print(f\"   Exception Type: {type(e).__name__}\")\n",
    "    \n",
    "    # Capture clean traceback to string buffer\n",
    "    print(f\"\\nüìÑ Full Stack Trace:\")\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    # Create string buffer and suppress stderr while formatting\n",
    "    error_buffer = io.StringIO()\n",
    "    sys.stderr = open(os.devnull, 'w')\n",
    "    try:\n",
    "        traceback.print_exc(file=error_buffer)\n",
    "    finally:\n",
    "        sys.stderr = original_stderr\n",
    "    \n",
    "    error_text = error_buffer.getvalue()\n",
    "    print(error_text)\n",
    "    print(\"-\" * 60)\n",
    "    \n",
    "    print(f\"\\n‚ö†Ô∏è  Common causes:\")\n",
    "    print(f\"   - Missing Microsoft Sentinel Contributor permissions\")\n",
    "    print(f\"   - Storage account access issues\")\n",
    "    print(f\"   - DataFrame schema incompatibility\")\n",
    "    print(f\"   See: https://learn.microsoft.com/en-us/azure/sentinel/roles\")\n",
    "finally:\n",
    "    # Ensure stderr is always restored\n",
    "    sys.stderr = original_stderr\n",
    "\n",
    "if not write_success:\n",
    "    print(f\"\\nüí° Your risk scores are still available for analysis!\")\n",
    "    print(f\"\\nüìä Sample Results (Top 10 Highest Risk Users):\")\n",
    "    output_df.select(\n",
    "        \"UserPrincipalName\",\n",
    "        \"department\",\n",
    "        \"total_risk_score\",\n",
    "        \"risk_level\",\n",
    "        \"signin_behavior_score\",\n",
    "        \"security_alert_score\"\n",
    "    ).orderBy(col(\"total_risk_score\").desc()).show(10, truncate=False)\n",
    "    \n",
    "    print(f\"\\nüìÅ To export to CSV:\")\n",
    "    print(f\"   pdf = output_df.toPandas()\")\n",
    "    print(f\"   pdf.to_csv('user_risk_scores.csv', index=False)\")\n",
    "    \n",
    "    print(f\"\\n‚úÖ Continue with Section 13 for sample queries\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medium pool (32 vCores) [Risk Score]",
   "language": "Python",
   "name": "MSGMedium"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
